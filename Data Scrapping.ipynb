{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%config InlineBackend.figure_formats = ['svg']  # or svg\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab Links of Movies From 2000 to 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.boxofficemojo.com/year/2000/?ref_=bo_yl_table_3', 'https://www.boxofficemojo.com/year/2001/?ref_=bo_yl_table_3', 'https://www.boxofficemojo.com/year/2002/?ref_=bo_yl_table_3', 'https://www.boxofficemojo.com/year/2003/?ref_=bo_yl_table_3', 'https://www.boxofficemojo.com/year/2004/?ref_=bo_yl_table_3', 'https://www.boxofficemojo.com/year/2005/?ref_=bo_yl_table_3', 'https://www.boxofficemojo.com/year/2006/?ref_=bo_yl_table_3', 'https://www.boxofficemojo.com/year/2007/?ref_=bo_yl_table_3', 'https://www.boxofficemojo.com/year/2008/?ref_=bo_yl_table_3', 'https://www.boxofficemojo.com/year/2009/?ref_=bo_yl_table_3', 'https://www.boxofficemojo.com/year/2010/?ref_=bo_yl_table_3', 'https://www.boxofficemojo.com/year/2011/?ref_=bo_yl_table_3', 'https://www.boxofficemojo.com/year/2012/?ref_=bo_yl_table_3', 'https://www.boxofficemojo.com/year/2013/?ref_=bo_yl_table_3', 'https://www.boxofficemojo.com/year/2014/?ref_=bo_yl_table_3', 'https://www.boxofficemojo.com/year/2015/?ref_=bo_yl_table_3', 'https://www.boxofficemojo.com/year/2016/?ref_=bo_yl_table_3', 'https://www.boxofficemojo.com/year/2017/?ref_=bo_yl_table_3', 'https://www.boxofficemojo.com/year/2018/?ref_=bo_yl_table_3']\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.boxofficemojo.com/year/{}/?ref_=bo_yl_table_3'\n",
    "urls = []\n",
    "for year in range(2000,2019):\n",
    "    urls.append(url.format(str(year)))\n",
    "print(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrapping Domestic Movies for year 2000 - 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_rows(urls):\n",
    "    rows = []\n",
    "    for url in urls:\n",
    "        response = requests.get(url)\n",
    "        page = response.text\n",
    "        Soup = BeautifulSoup(page,'lxml')\n",
    "        table = Soup.find('table')\n",
    "        for row in table.find_all('tr')[1:]:\n",
    "            rows.append(row)\n",
    "    return rows\n",
    "    \n",
    "rows = get_all_rows(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3800"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Table From Page / Scrape Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>domestic_gross</th>\n",
       "      <th>distributor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>How the Grinch Stole Christmas</td>\n",
       "      <td>/release/rl3059189249/?ref_=bo_yld_table_1</td>\n",
       "      <td>251628705</td>\n",
       "      <td>Universal Pictures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Mission: Impossible II</td>\n",
       "      <td>/release/rl1600292353/?ref_=bo_yld_table_2</td>\n",
       "      <td>215409889</td>\n",
       "      <td>Paramount Pictures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Gladiator</td>\n",
       "      <td>/release/rl2136245761/?ref_=bo_yld_table_3</td>\n",
       "      <td>186610052</td>\n",
       "      <td>DreamWorks Distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>The Perfect Storm</td>\n",
       "      <td>/release/rl661161473/?ref_=bo_yld_table_4</td>\n",
       "      <td>182618434</td>\n",
       "      <td>Warner Bros.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Meet the Parents</td>\n",
       "      <td>/release/rl677545473/?ref_=bo_yld_table_5</td>\n",
       "      <td>161146255</td>\n",
       "      <td>Universal Pictures</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      link  \\\n",
       "How the Grinch Stole Christmas  /release/rl3059189249/?ref_=bo_yld_table_1   \n",
       "Mission: Impossible II          /release/rl1600292353/?ref_=bo_yld_table_2   \n",
       "Gladiator                       /release/rl2136245761/?ref_=bo_yld_table_3   \n",
       "The Perfect Storm                /release/rl661161473/?ref_=bo_yld_table_4   \n",
       "Meet the Parents                 /release/rl677545473/?ref_=bo_yld_table_5   \n",
       "\n",
       "                               domestic_gross              distributor  \n",
       "How the Grinch Stole Christmas      251628705       Universal Pictures  \n",
       "Mission: Impossible II              215409889       Paramount Pictures  \n",
       "Gladiator                           186610052  DreamWorks Distribution  \n",
       "The Perfect Storm                   182618434             Warner Bros.  \n",
       "Meet the Parents                    161146255       Universal Pictures  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def money_to_int(moneystring):\n",
    "    moneystring = moneystring.replace('$', '').replace(',', '')\n",
    "    return int(moneystring)\n",
    "\n",
    "def generate_movies_dict(rows):\n",
    "    movies = {}\n",
    "    for row in rows:\n",
    "        items = row.find_all('td')\n",
    "        link = items[1].find('a')\n",
    "        title, url = link.text, link['href']\n",
    "        \n",
    "        # avoid repeted titles \n",
    "        if title in movies.keys():\n",
    "            continue\n",
    "        else:\n",
    "            domestic_gross = items[5].text\n",
    "            domestic_gross = money_to_int(domestic_gross)\n",
    "            distributor = items[9].text[:-2]\n",
    "            movies[title] = [url,domestic_gross, distributor]\n",
    "    return movies\n",
    "\n",
    "\n",
    "movies = generate_movies_dict(rows)\n",
    "movies_df = pd.DataFrame(movies).T  #transpose\n",
    "movies_df.columns =['link', \n",
    "                    'domestic_gross','distributor']\n",
    "\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Helper Functions to Scrapp the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dateutil.parser\n",
    "import re\n",
    "\n",
    "def get_movie_value(soup, field_name):\n",
    "    \n",
    "    '''Grab a value from Box Office Mojo HTML\n",
    "    \n",
    "    Takes a string attribute of a movie on the page and returns the string in\n",
    "    the next sibling object (the value for that attribute) or None if nothing is found.\n",
    "    '''\n",
    "    \n",
    "    obj = soup.find(text=re.compile(field_name))\n",
    "    \n",
    "    if not obj: \n",
    "        return None\n",
    "    \n",
    "    # this works for most of the values\n",
    "    next_element = obj.findNext()\n",
    "    \n",
    "        \n",
    "    if next_element:\n",
    "        if field_name is 'IMDbPro':\n",
    "            return next_element.find_all('a')[0].get('href')\n",
    "        else:\n",
    "            return next_element.text \n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "\n",
    "def runtime_to_minutes(runtimestring):\n",
    "    runtime = runtimestring.split()\n",
    "    try:\n",
    "        minutes = int(runtime[0])*60 + int(runtime[2])\n",
    "        return minutes\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_movie_dict(link):\n",
    "    '''\n",
    "    From BoxOfficeMojo link stub, request movie html, parse with BeautifulSoup, and\n",
    "    collect \n",
    "        - title \n",
    "        - domestic_gross\n",
    "        - total gross\n",
    "        - budget\n",
    "        - runtime \n",
    "        - Genres\n",
    "        - MPAA rating\n",
    "        -distributor\n",
    "    Return information as a dictionary.\n",
    "    '''\n",
    "    \n",
    "    base_url = 'https://www.boxofficemojo.com'\n",
    "    \n",
    "    #Create full url to scrape\n",
    "    url = base_url + link\n",
    "    \n",
    "    #Request HTML and parse\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page,\"lxml\")\n",
    "\n",
    "    \n",
    "    headers = ['movie_title', 'domestic_gross', 'total_gross','budget', \n",
    "               'runtime_minutes', 'genres','rating', 'imd_url','distributor']\n",
    "    \n",
    "    #Get title\n",
    "    title_string = soup.find('title').text\n",
    "    title = title_string.split('-')[0].strip()\n",
    "\n",
    "    #Get World Wide gross\n",
    "    head = soup.find(class_='mojo-performance-summary-table').find_all('span', class_='money')\n",
    "    \n",
    "    #Domestic Gross\n",
    "    #print(len(head))\n",
    "    raw_domestic_gross = (head[0].text)\n",
    "    domestic_gross = money_to_int(raw_domestic_gross)\n",
    "    \n",
    "    #Gross Total\n",
    "    if len(head) == 3:\n",
    "        raw_worldwide_total_gross = (head[2].text\n",
    "                               )\n",
    "        total_gross = money_to_int(raw_worldwide_total_gross)\n",
    "    elif (len(head) == 2) and (head[0].txt == head[1].txt):\n",
    "        raw_worldwide_total_gross = (head[1].txt)\n",
    "        total_gross = money_to_int(raw_worldwide_total_gross)\n",
    "    else:\n",
    "        total_gross = None\n",
    "        \n",
    "    \n",
    "    # Get Budget\n",
    "    raw_budget = get_movie_value(soup, 'Budget')\n",
    "    if raw_budget is not None:\n",
    "        budget = money_to_int(raw_budget)\n",
    "    else:\n",
    "        budget = raw_budget\n",
    "    #Get runtime\n",
    "    raw_runtime = get_movie_value(soup,'Running')\n",
    "    runtime = runtime_to_minutes(raw_runtime)\n",
    "    # Considering the first Genres\n",
    "    genres = get_movie_value(soup, 'Genres')\n",
    "    genres = genres.split('\\n')[0]\n",
    "    #Get rating\n",
    "    rating = get_movie_value(soup,'MPAA')\n",
    "    imd_url = get_movie_value(soup, 'IMDbPro')\n",
    "    #print(f'print link {next_link}')\n",
    "    #Create movie dictionary and return\n",
    "    movie_dict = dict(zip(headers, [title, domestic_gross, total_gross, budget, runtime, genres, rating, imd_url]))\n",
    "\n",
    "    return movie_dict\n",
    "\n",
    "def scrape_imdbpro(url):\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    imd_soup = BeautifulSoup(page,\"lxml\")\n",
    "    \n",
    "    head = imd_soup.find_all('div', id='const_page_summary_section')\n",
    "    imd_dict = {}\n",
    "    spans = head[0].find_all('span')\n",
    "    for i, span in enumerate(spans):\n",
    "        #print(f'{i}  {span.text}')\n",
    "        if 'Director' in span.text:\n",
    "            if 'director' not in imd_dict:\n",
    "                imd_dict['director'] = spans[i+1].text\n",
    "        if 'Cinematographer' in span.text:\n",
    "             imd_dict['cinematographer'] = spans[i+1].text\n",
    "        if 'Producer' in span.text:\n",
    "            imd_dict['producers'] = spans[i+1].text        \n",
    "    return imd_dict\n",
    "\n",
    "def scrape_opening(url):\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    imd_soup = BeautifulSoup(page,\"lxml\")\n",
    "    head = imd_soup.find_all('span', class_='a-color-secondary')\n",
    "    return head\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_info_list = []\n",
    "for i, link in enumerate(movies_df.link):\n",
    "    try:\n",
    "        movie_dict = get_movie_dict(link)\n",
    "        #print(movie_dict)\n",
    "        imd_dict = scrape_imdbpro(movie_dict['imd_url'])\n",
    "        imd_dict['distributor'] = movies_df.iloc[i,2]\n",
    "        #print(imd_dict)\n",
    "        movies_info_list.append( dict(movie_dict, **imd_dict))\n",
    "    except:\n",
    "        print(f'Error in {link}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save scrapped data in data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_info_list[0]\n",
    "scrapped_data = pd.DataFrame(movies_info_list)\n",
    "scrapped_data.to_csv(r'.\\data\\scrapped_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
